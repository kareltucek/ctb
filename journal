Sat May  2 11:42:39 CEST 2015
=============================
The basic idea is the following:

Backend will serve as a library frontend. It will manage an instruction table, loading and processing of all data. It will be parametrized by a type of the instruction table and loader. Backend will forward arguments to the graph and instruction table functions.

Loader will represent a single consistent input method. Loaders may be swapped over the backend. E.g. one loader may handle xml files while another plain text files. Loader will construct the instruction table and graph using their public methods. Instruction table may be replaced by a self-contained instruction table - in that case backend should be parametrized by a loader with an empty call to the method loading the instab.

Writer represents a block of code and provides methods for simple generation and formating of code. It is basically a bit tweaked string.

Instruction table will hold the code generation information.

Graph will hold the graph with appropriate links to the instruction table. Graph may be split into Graph and Generator classes in future.

Code for generation will be held as part of xml files and will use a shell like evaluation of parameters using printf like syntax with predefined meaning of arguments.

Sat May  9 12:40:39 CEST 2015
=============================
Today I've found a problem of the writer concept. The problem is that a simple writer can work only with one abstract level of aliases, which means that deeper evaluation has to be known to all levels (e.g. variable names and indexes have tobe distributed into the instruction table xml description, which though should describe instructions without carrying the resulting code as its own dependency). As an answer to this problem I decide to introduce a concept of a model. Model is a static extension to the writer class, representing a consistent output system. Exampli gratia we may have one model representing a bobox box or project or a testing (nonbobox) suit dedicated to the code generation. Model may have multiple levels and should be able to evaluate abstract aliases on multiple levels. For instance one level may carry a structure of file templates and provide a mechanism of putting these together. Another level may translate abstract instruction table arguments into actual variable names with corresponding indices. 

Proposed implementation:
- Make all generating graph funcions templated, taking an instance of a mode/writer, which it will then use for output.
- Generalize alias evaluation by adding a static map to a model. Lets consider print("$output = $arg1", value). Model will have defined an alias of an $output to "$outname$outindex[j]", $outname to "out_list_", $outindex to "$3" and $arg1 to "$4". This will be evaluated by a recursive sequence of print calls out of which all will carry the same parameter list, so that the leaf arguments $3,$4 etc will be evaluated according to the caller's context while its abstract meaning will be given by the model.
- Model will provide a main method, which will generate the resulting code. This method will be called by backend's process and will take a graph as its argument. The main method will then write its code and call graph's generate method parametrized by itself, so that the code generation made by graph will get evaluated by the alias definitions of the model itself.


Mon May 11 20:33:37 CEST 2015
=============================
Today I have refactored the writer class. Now it resolves aliases in arguments as well (a real variadic list hell). Furthermore I started implementing the SSE instructions. 

I had sorted out type conversions. The data producer is always responsible for providing the data in all required widths. The output width is the main width specifier for a regular node.

All instructions produced by one node are packed in the final ordering. Whe could change the ordering to produce less spill code by moving the induction variable above the tree crawler function -> then every node would have to remember the actual number of iterations produced and the crawler would have to respect these, possibly returning to any node multiple times, going through segments between merges. Compiler should be able to take care of this automatically.

I consider adding a 'custom code' field into the xml structure to allow user to define his own call structure e.g. when he needs any temporary variables. There have already been problems with conversions, because it may not be possible to implement split instruction in a generic way (i.e. by a common template for both halves which are produced).

Also I considered the control flow version of this problem. The proposed solution is to create one more graph, which will hold all components determined by conditional cuts. This will hold the code and various cut flags for every one of these. The final code will be produced by DFS on this graph. The generic part of output will have to be generalized using more templates somehow in order to take care of ingeneral control flow structures. 


Tue May 12 16:45:32 CEST 2015
=============================
New problem has occured with the right hand dollar sign. It will have to be resolved by a manual flag (we are out of control of how many times it may be processed and thus we dont shorten the $$ to $ until final output unless explicitly asked for. The problem occured when constructing intermediate names in the split/merge functionality.


Thu May 14 12:30:39 CEST 2015
=============================
Today I have split the original grap into a generator and a graph class. Also I have created a proxy class wrapper, which allows read-only access to foreign classes and write access to owners of an object. I failed to do this transparently (as I originally itended).

Wed Jun  3 10:02:58 CEST 2015
=============================
In the past two weeks I implemented a conversion path search and wrote some documentation.

Fri Jun 26 11:30:16 CEST 2015
=============================
Today I am considering how to actually import data. Some type abstraction seems to be necessary (e.g. to import all instructions of the same format (e.g. add_pi[u]{32|60|128}($arg1, $arg2)) by only one line. For this purpose csv format seems to be much more versatile, since it allows easy 'foreach' expansions. As the result I am implementing a csv importer with a perl expansion script.

Also today I noticed a few problems with the writer design - mainly ingenerality. At the moment I would like to be able to use it simply with multiple output formats, but I have hardcoded syntax structure. 

Next thing I ran into is a serious problem with loading system, which does not allow combining multiple loading systems. Fortunately fix seems to be simple.


Sat Jul 25 10:56:04 CEST 2015
=============================
Yesterday I finished the csv preprocessor discussed in the pevious entry.

Now I have arrived at another design problem. Instruction table does not 


Thu Jul 30 10:01:27 CEST 2015
=============================
I am implementing a csv loader and exporter atm. Due to the need of exporting data most of members of instruction_table have to be made publicly readable. 

The next thing to be done is generalization of the command line interface. The current one is totaly ingeneral. For this, the model/loader management will have to be improved. Establishing functional hash tables holding template-constructed functors seems to be a good idea for this.


Sun Aug  2 19:49:21 CEST 2015
=============================
Note that model/loader template signatures have to take form of "typename...". All other parameters have to be packed.


Tue Aug 11 14:19:34 CEST 2015
=============================
Back again. Today I started testing of the csv loader and bumped into problems with ingenerality of the writer. The strings to be imported/exported tended to be expanded when they should not have been. As a result I had to implement explicit 'dolar_mode' control for both input and output actions of writer. 

Another thing I have done is generalizing exception handling. I have created two global functions which would let me change mechanics of exception throwing simply and also have written multiple layers of error handling.


Wed Aug 12 19:19:15 CEST 2015
=============================
I restructured the directory structure.

Exception handling was improved in order to report helpfully errors in (csv) instruction tables.

Also I have created basic C instruction table.

Now I am working on tags and custom code support, because I need to type in tags while creating the sse instruction set.


Thu Aug 13 14:44:01 CEST 2015
=============================
I am introducing new structure: a tagmaster. Motivation is described in tagmaster.h.


Fri Aug 14 11:55:03 CEST 2015
=============================
It seems to be a good moment to generalize writer once more. I am moving cartesian expansion directly into the writer. Next thing I am doing is implementing an expansion of arithmetic expressions (I will need it anyway). For that a new class parser have been written. Again many things are moving around due to these 'details'.

Tue Aug 18 12:49:30 CEST 2015
=============================
I have been working on sse instruction table for some time.

Now we will need a way of testing these tables. My approach is creating a new loader, which will search through an instruction table as if it were a graph and generate a graph. 

I should have written this entire project in perl... Generalizing command line parser using functors atm... (I need to make test graph accessible from text environment, but for that I need a little different api).


Tue Sep  8 22:10:03 CEST 2015
=============================
During the last two weeks I have been writting the C sse table and its testing environment.

Regarding the C tables, one problem I arrived at a few days ago is a bool structure. Bools and data have to be organized in an 'alternating' structure in canonical order. Reordering wont work because doubles are always in canonical order. Nonalternating structure will cause conflicts in cases like (int_8<2> < int_8<2>) == (double<2> > double <2>). As the result I am impelementing two boolean types. One for logical operations with numbers - noncompressed byte boolean type - and one compressed for pure boolean operations - 128 bool vectors. (Oh yeah, I know I have been told about this problem already!)

Graph testing loader has been written. Also a 'compile test' was added. This option will cause generator to generate only the first vector instruction. This will prevent situations like 128 times the same error.

Also I have written some two formal A4 pages on solving the control flow problem. I believe DAGs with trivial split and join operations are solveable without greater problems. Unfortunately overhead of such code is significant. I dont believe this algorithm to be advantegous with the x86 sse instruction set.

Thu Sep 10 14:41:18 CEST 2015
=============================
Today I have been writting support for generic splits/joins. I had to add 3 indexes to the standard variables available in the generator's alias environment:
  - output vector index
  - input vector index
  - internal vector index = iteration over the generic elements = difference of output and input indices.
Getting this sorted out took me a while...

Note that this change changes semantics of custom code for splits and joins. Semanticaly logical is using custom join with generic splits, but the inverse operations are supported too.

Also I had to add a real 'dynamic' list support to the writer environment. Now writer accepts stringlists in its parameters. These are indexed in order as if these lists were flattened. This probably is not the best idea since it still prevents usage of multiple lists in a single call. This was needed for the custom join and split.


Sun Sep 13 15:20:43 CEST 2015
=============================
Since Thursday I've been debugging instruction tables.

I have written new alias environment, intended as an improved 'simple' which would allow consistent testing of behaviour of instruction tables. That means which would be able to produce multiple width algorithms (assuming that basic C is implemented correctly) and compare their results.

Today I have written runtime debug support. That means:
- Added flag 'debug' which identifies debug operations.
- A debug operation is an operation which takes one input and behaves as an output, which is intended to be either written out to terminal or checked against static results. Debug operations are not subject to width conversions. 
- Added new command 'adddebug' which creates and hooks debug nodes to either all vertices of a graph or to a set of nodes which are in a distance less than supplemented 'depth' parameter from vertices specified by argument list.


Tue Sep 22 20:29:55 CEST 2015
=============================
Since the previous entry I have debugged the rest of the C/sse instruction table. 

Today I arrived at a problem while modyfying the bobox model. Specifically I need to define different LD versions for aligned and unaligned swiches. The problem is with generality of such swich since the table should remain as model-independent as possible. At last I arrived at a conclusion that correct approach will be not to mess with internal generation of instructions by model. Instead there will be multiple versions of the instruction in the table marked by different tags and models will define their own required tag sets. There comes a problem, because the tag handler was originally intended to exist only in one instance and be constant. Finally I have rewrittent it into runtime polymorphic class and modified instruction table so that it can hold an arbitrary number of tag handlers. Before every generation the instruction table's instruction's state is updated.


Fri Sep 25 12:52:10 CEST 2015
=============================
Yesterday I noticed another problem. I need to generate preload instructions with width dependent on a curent graph and only for the lowest vector variable. For that I need two modifications:
- Selective generation. Passing a 'bool callback(vertex)' callback to the generator seems to be a good solution.
- Still I need to generate this only for the first variable of the load methods -> I need a custom mode on the generate method. Generalization of generator and instruction table for functional handling seems to be a good method of dealing with the problem. For now I will most likely add just a conditional switch on a new 'flag' 

Flags field seems to be becoming a bit redundant. The only difference to the tags fields is that flags are currently used for more internal stuff.


Sat Feb 27 21:12:30 CET 2016
============================
Today I have been finding out what I have been doing last time I had found time for this. Well, apparently I had been extending api of graph to support edge removal and factorisation. 

I believe I have finished everything neccessary (for the time being) in the graph. During this process I have came across a serious problem - the ptr to ptr implementation edges did not identify the edge positions unambiguously. As the result I had to replace simple pointers by structures.

During this process I had been trying to humanize the C++ syntax using templates and macros. Most of ideas failed on the fact that simple types cant be used as classes. As the result I had written just two small macros - one which makes structure behave as a pointer by default (so we can still use the same syntax as before with edges) and a second one which creates a trivial identity constructor-like function, which makes structures constructible in an almost sensible manner - e.g. by make_edge({a, b, c}) syntax. 

Also I have decided to throw out proxies entirely. I believe this will simplify further development, since there will no longer be any cases of unsolveable access conflicts or of trivial syntax typos masked as who-knows-whats. I am not happy about that, but for now I do not see any better solution.


Sun Feb 28 19:25:11 CET 2016
============================
Today I have been trying to finish the basic control flow expansions. During this process I have came across one serious problem with the edge representation. As the result edges are now represented as separate objects containing all their information.


Wed Mar  2 08:45:34 CET 2016
============================
For control flow version we will need to eliminate all cycles in factor graph. (factor graph is created by factorisation over graph with removed control flow boundaries E.g. a split ) (describe consistency requirements) The proposed algorithm is the following:

while ( cycle_exists ) //dont forget to construct new factor graph
{
  v = first partition in pseudo topological ordering (where partitions are ordered by topological ordering of their childrens)
  follow all outputs leading from v and colour all found vertices red
  colour v and all its predecesors green
  colour all successors of green to green as well, but do not pass partition boundaries
  now use the coloured vertices to identify a cut in *all* partitions
  put a buffer on all edges in the cut
}
//cf contains some notes -> we may want explain this in detail in respect to our crawling methods

(the complexity is apparently n^4 since cycle check will take n^3 and we may repeat algorithm n times)

Note that one iteration per partition may not be sufficient! On the other hand every iteration will increase number of partitions by one. We may observe that added buffers may not create another cycle (they have degree 1) and thus their connecting edges cannot be contained in any future cut. Thus the number of iterations of this algorithm is bound by number of vertices of the *original* graph.

Also note that we may want to determine size of a buffer by its context (by the longest path leading between any previous and next partition)

Ensuring the pseudotopological ordering of components. It suficces to perform it from within of a topological pass over the edge classes 1 and 2.

Today I am going to ensure that parittions are sorted pseudo-topologically (I believe they should already be!), implement the cycle search algorithm and the splitting algorithm. 

!!!Currently we support only 1:1 width explicit instructions. In case we add support for general widths we may also want to be able to optimize width choice. Sensible way to do this seems to be by standard critical-path algorithm (either in respect to number of instructions or their cost).)

!!!This algorithm does not provide a minimal cut. We may propose an algorithm for this

!!!Observation - this algorithm will work if we start from arbitrary component on the cycle


TODO
====
// TODO
//conversions - find nontrivial conversion path -implemented
//output node ordering - dropped
//abstract output syntax formatting - done
//export mechanics - hopefully done
//general conversion interface - hopefully done (not yet tested)
control flow support
-> //graph factorization - done
-> //general composite instruction support in instruction tables - done
-> //preprocessors - standalone graph preprocessors - done
-> graph partitioning -> how? Most likely on the 'generator' level. The generator will get support for creating directly code of the partitions.
-> //extend graph api by reference driven edits and by removes - done
-> //write preprocessor for a control flow set
-> generator
-> create cf generators -> what should these do? These should most likely be alias-env specific template compositors ('inserted between current generator and aliasenvs'); possibly 
-> maybe cf-generators should be insertable as the original generators?
autoconversion for internal types (bool<->ssebool)
bool <-> conversion instructions
"spillcode" like cost optimizations

// TODO - minors
//stream support - hopefully done
//ensure correct clearing - done
//allow custom combination of loaders - done
//tag support - done
//custom code support - done
//unit tests for export mechanics (and dependencies) - done
//solve template ingenerality of register methods - this conflict has never existed
//switch to nonstatic loaders - done
//runtime debug support - done
split commandline interface from programming interface (taskmaster conflicts at the moment)
writer - callback driven parenthess expansion
forward all agrument from print directly to aliasenv so that generation environment can do its (own) magic
  +
generic id type handling
solve output of two consecutive words elegantly
test cmp on virtual
pass arguments to loaders as a stringlist
organize macro files
generalize generator and instruction table in order to be able to use general instruction classes (into functional hash table)
optimize tag handling; decoding of tags should be unified and moved a few call-layers higher

