Since the cause of ineffectiveness of the previous proposal is the requirement stating that data should be processed in order, we will investigate the same problem without this condition. 


If we simply dropped the condition, i.e., by letting merges merge in any order, there would arise a problem that data may get reordered differently in different branches. E.g., like in the following diagram.

\graph{ordered_conflict}{Computation which mixes data of different data rows together.}

This problem may be addressed by ensuring that data rows are always handled as one unit, meaning that every split will be performed on all data except data that are not used any further.

\mybegindef{seqform}{Sequential form of control flow}
We will say that a control flow of a flow graph $G(V,E)$ with control-flow nodes expanded and cycles removed is in \emph{sequential form} if the following conditions hold.
\begin{itemize}
  \item All inputs of $G$ are in the same component.
  \item At least one of the following conditions holds for every component $C$ of $G$: 
    \begin{itemize}
      \item $C$ does not have any input from another component of $G$.
      \item All inputs of $C$ are unordered merge nodes such that corresponding inputs of any two input merge nodes of $C$ lead into the same partition of $G$.
      \item All inputs of $C$ are standard merge nodes such that corresponding inputs of any two input merge nodes of $C$ lead into the same partition of $G$ and the at the same time all these merges use the same condition.
      \item All inputs of $C$ are explicit queues leading from another component $D$ of $G$.
    \end{itemize}
  \item At least one of the following conditions holds for every component $C$ of $G$: 
    \begin{itemize}
      \item $C$ does not have any output going into another component of $G$.
      \item All outputs of $C$ are split nodes such that corresponding outputs of any two output split nodes of $C$ lead into the same partition of $G$ and at the same time all these splits use the same condition.
      \item All outputs of $C$ are explicit queues leading into another component $D$ of $G$.
    \end{itemize}
\end{itemize}
\myenddef

\mybegindef{nodetypes2}{Unordered merge}
\begin{description}
  \item [unordered merge operation] will have the same semantic meaning as the standard merge or loop merge operation except it will not take any condition input. This operation may merge streams in an arbitrary but deterministic manner.
\end{description}
\myenddef

It is not clear whether every consistent flow graph can be transformed into a flow graph with control flow in sequential form. What is clear is that there exists a nontrivial class of flow graphs which are in this form.

\mybeginobs{seqschemes}{Consistency of schemes with control flow in sequential form}
  Let $G(V,E)$ be a flow graph s.t. the following conditions hold.
  \begin{itemize}
    \item $G$ is consistent according to \emph{consistency of schemes} (definition \ref{def:schemeconsistency}).
    \item $G$ uses only unordered versions of merge nodes in place of standard merge or loop merge nodes.
    \item All input nodes of $G$ are in the preamble.
  \end {itemize} 
  Then $G$ may be transformed into a consistent flow graph with control flow in sequential form. This may be achieved by copying the scheme in question onto every path between \emph{preamble} and \emph{epilogue} and joining all newly created branch or loop bodies by means of the \emph{scheme sequencing} observation. We may join these by adding any regular operation which does not alter the semantics of $G$.
  \begin{proof} 
  Sequentiality of the resulting control flow follows directly from definitions.
  \end{proof}
\myendobs

\mybeginobs{seqschemenestingsequencing}{Unordered scheme nesting and sequencing}
  Both \emph{scheme nesting} and \emph{scheme sequencing} will produce graphs with control flow in sequential form as long as:
  \begin{itemize}
    \item All input graphs have control flow in sequential form and all paths from \emph{preambles} to \emph{epilogues} are transformed in the means of the previous observation.
    \item The condition requiring all inputs to be in the same component (w.r.t. regularity and connectedness) is not voided.
  \end {itemize} 
  \begin{proof} 
  The key observation is that the previous transformation necessarily splits \emph{preamble} from \emph{epilogue} (with respect to regularity of nodes). Thus, nesting of a new scheme into a component will never create two parallel schemes except for schemes which comply with the \emph{scheme sequencing}.
  \end{proof}
\myendobs

%\begin{claim}
%Let $G(V,E)$ with $I$ and $O$ be a consistent flow graph with control flow in sequenced form. 
%\end{claim}

Consider the following problem:

  \mybeginprob{unorderedproblem}{Unordered realisation of control flow}
      Let $G(V,E)$ be a consistent flow graph with $O$ and $I$ defined as in the \emph{vectorized code generation}. Let $G$ use only the following types of nodes: regular nodes (including input and output nodes), split, unordered merge and loop condition. Let all loops conditions be used by means of the \emph{loop condition} scheme defined by \ref{def:cfconstructs} and let the control flow of $G$ be in sequential form. Let all inputs of $G$ be in one component. Also, let control flow nodes of $G$ be expanded and let the factor graph of $G$ be acyclic. We wish to generate code which will realise graph $G$ on an arbitrary number of data rows, utilising SIMD instructions whenever possible. 
\myendprob

  We are almost ready to show that flow graphs with control flow in sequential form may be realised very easily without any need of pull semantics. The only problem we need to address is the problem of buffer sizes. Apparently, buffer size $2*w-1$ suffices to accept one (full) vector of data rows in a situation in which there is not enough data for vectorized processal of the next component. One problem lays in loops.  Consider a loop with nested branching. For instance:

  \graph{fullloop}{Illustration of a loop which may cause a problem if buffer capacities were not chosen cautiously.}

  It may easily happen that all branching bodies\footnote{More precisely their input and output buffers.} get filled at some point. The problem comes when we process the data from these branching bodies because data from all bodies may be directed into the same branch next time they enter the body of the loop. Thus, some path (or more precisely entire cycle) may get \emph{entirely} filled. This problem may be solved by limiting the amount of data present in the loop to the capacity of the shortest cycle of the loop. We have already presented this functionality in the definition of the loop condition (definition \ref{def:nodetypes1}). 

  Since we now limit the amount of data in loops, there may arise another problem. The problem is that all data rows may get distributed in such way that no buffer contains at least $w$ data rows. This could be solved by employment of the pull semantics and by enabling the third input of merge nodes again. This third input would then be used solely for the purpose of \emph{finding} data. Another way is ensuring that sufficient amount of data fits into the loop. This may be achieved by increasing the size of some buffer which is shared by all paths.

  \mybegindef{buffergraph}{Buffer size-allocation graph}
  Let $G$ be a flow graph. Let $G'$ be a flow graph created from $G$ by mapping of all its layer 2 edges to layer 1.
      We will use the term \emph{buffer size-allocation graph} of $G$ for a factor graph of $G'$.
\myenddef


  \mybegindef{capacities}{Construction of capacities}
      Let $H(V,E)$ be a \emph{buffer size-allocation graph} of a flow graph $G(V',E')$ defined as in the \emph{unordered realisation of control flow} problem, let $w \in \N$ be a number representing vector size. We shall define the following functions:
  \begin{itemize}
    \item $multiPath: V x V \arrow \powerset (H)$ as $multiPath(u,v) = \bigcup_{\substack{P \subseteq H \\ \text{path from u to v}}} P$\footnote{We understand a path to be a connected subgraph with degrees less or equal two, therefore, we have just implicitly required that this path does not enter a single vertex twice.}.
    \item $bufferCapacity: E \arrow \N$ as a function denoting the actual capacity assigned to all buffers between components connected by an edge of $E$ 
    \item $apparentCapacity: E \arrow \N$ as a function denoting the apparent capacity assigned to all buffers between components connected by an edge of $E$.
    \item $safeCapacity: E \arrow \N$ as a function denoting the number of data rows a buffer is guaranteed to accept.
    \item $safeCapacity: V \times V \arrow \N$ as a function denoting the number of data rows $S = multiPath(u,v)$ guarantees to accept. More precisely, the number of data rows the component $u$ can push into $S$ in vectorized manner without overfilling any buffers and without the component $v$ having to process data. 
    %\item $capacity: V \times V \arrow \N$ as a function denoting the actual capacity of a $multiPath(u,v)$.
    \item $capacity: \powerset(H) \arrow \N$ as a function denoting the actual capacity of a subgraph of $H$.
    \item $limit: V' \arrow \N$ as a partial function denoting the number of data rows allowed into a loop managed by a loop condition, as defined in \ref{def:nodetypes1}.
  \end{itemize}


  Let the values be assigned according to the following rules:
  \begin{itemize}
    \item Let $e \in E$ be an edge which does not connect components managed by the same loop condition. We shall refer to $e$ as to $loop balancing buffer$ later.
    \begin{itemize}
      \item \myexpr{bufferCapacity(e) := 2*w}
      \item \myexpr{apparentCapacity(e) := bufferCapacity(e)}
      \item \myexpr{safeCapacity(e) := bufferCapacity(e) - w + 1}
        
        This is due to the fact that vectorized version of the algorithm \ref{alg:crawler} requires at least $w$ empty slots in its data sinks.

    \end{itemize}
    \item \myexpr{ safeCapacity(u, v) := \min_{\substack{P \subseteq H\\ \text{a path from u to v}}} \sum_{\substack{e \in E(P)}} safeCapacity(e) }
    \item \myexpr{ capacity(S) := \sum_{e \in S} apparentCapacity(e) } 
    \item Let $s$ be a loop condition managing partitions $u$ and $v$ such that $u$ consists of merge nodes and $v$ consists of split nodes. Let $e \sim (u,v)$.
    \begin{itemize}
      \item \myexpr{ limit(s) := capacity(multipath(v,u))  - capacity(P)  + (| P | + 1) * (w-1) + 1 } 

      Where $P$ is a path from $u$ to $v$ such that $capacity(P)$ is minimal.

        Assume that the loop defined by node $s$ contains $limit(s)$ data rows. Then even the shortest cycle on the loop contains a buffer which contains at least $w$ elements. The multipath corresponds to the 'loop body'. 
        
        The first difference of capacities `fills' all buffers except for buffers on the path with least capacity. 
        
        The $| P +1 | * (w-1)$ `fills' every buffer by $w-1$ data rows. 
        
        The first $+1$ in |P + 1| is for the buffer between v and u. 
        
        The last $+1$ is to make at least one buffer contain $w$ data rows.

      \item \myexpr{ bufferCapacity(e) :=  \ \ limit(s)  - safeCapacity(v,u)  + (w-1) + w }
        
        This ensures that safeCapacity of the entire loop is at least $limit(s) + w$. 
      \item \myexpr{ apparentCapacity(e) := limit(s) }
        
        This stands for the capacity of the entire loop since the edge e is the one which will be counted
      \item \myexpr{ safeCapacity(e) := limit(s) - w + 1 }
    \end{itemize}
  \end{itemize}
\myenddef

\mybeginclaim{buffercapacity}{Consistency of buffer capacities}
We claim that $bufferCapacity$ function is well defined, i.e., is defined for every buffer in $G$ and the value is determined unambiguously.
  \begin{proof}
    Apparently, assignment of capacity of the edges from the loop scheme depends on assignment of capacities of all buffers in the body of the loop. Loop nesting may be represented by an oriented tree. Every oriented tree has a topological ordering, which may be used to assign these functions.
  \end{proof}
\myendclaim

  Although we have (approximately) doubled the actual capacity of buffers of every loop, the apparent capacities have remained in $O(n)$ with respect to sizes of bodies of the loops. This means that the memory consumption should still remain reasonable. If we assume that the size of bodies decreases with quotient $q$ with respect to nesting, then the resulting memory consumption is $n*(1+\sum_{i=0}^{\infty}q^i)$. With $q=1/2$, which is a reasonable expectation, this means that memory consumption trebles. Unfortunately, the new worst-case memory bound is $O(n^2)$.

\mybeginclaim{capacityproof}{Complexity of buffer size allocation}
  Let $G$, $H$ and $bufferCapacity$ be defined as in definition \ref{def:capacities}. Let $n=| V(G) |$. We claim that capacity required by $G$ is in $O(n^2)$. 
  \begin{proof}\ 
    \begin{itemize}
      \item Capacity of the balancing buffer of every loop is at most the capacity of the loop body. This holds since the limit is at most capacity of the body.
      \item Capacity of the balancing buffer does not affect any other buffers since the apparent capacity of the loop remains the same.
      \item Thus, every loop contained in $G$ may allocate at most $O(n)$ memory for its balancing buffer.
    \end{itemize}
  \end{proof}
\myendclaim

This upper bound seems to be tight. Consider $O(n/2)$\footnote{Wich is equivalent to $O(n)$ except for semantical information it carries.} loop schemes nested alternatingly with the branching scheme in such manner that always only one branch contains a loop. Let the innermost body be of size $n/2$. This is shown in figure \ref{fig:buffercounter}. This setup will cause all loops to allocate an amount of space corresponding to the capacity of the innermost body.

\graph{buffercounter}{Worst-case memory-consumption scenario}

Note that a simple nesting of loops would not suffice, since the only path through the loop body would lead through the next loop body and therefore would get subtracted in the computation of $limit$. The fact that we cannot subtract the $limit$ in the scenario with branching is caused exactly by the two points discussed earlier:
\begin{itemize}
  \item The crawler does not know where data are located.
  \item There has to be sufficient capacity in case that the inner loop produces data which will be directed to the second branch in next iteration. 
\end{itemize}

It is possible that this upper-bound may be reduced by introduction of mechanism which would purposefully plan the path of the crawler. We do not have any proposal at the moment.
  
  %till in $O(n)$ with respect to the size of our input. \footnote{To be more precise the function resembles sum of a geometric serie with quotient smaller than one. Quotient 0.5 (quite realistic one) would mean treble memory consumption.}
  %Although we have (approximately) doubled the actual capacity of buffers of every loop, the apparent capacities have remained in $O(n)$ with respect to sizes of bodies of the loops. This means that the memory consumption is still in $O(n)$ with respect to the size of our input. \footnote{To be more precise the function resembles sum of a geometric serie with quotient smaller than one. Quotient 0.5 (quite realistic one) would mean treble memory consumption.}


\begin{rem}
  Note that the buffer capacities may be easily computed by an inverse topological pass of a factor graph of G. 
\end{rem}


%  \begin{itemize}
%    \item \emph{ capacity of a subgraph} $S \subseteq H$, i.e., $subgraphCapacity: \powerset(H) \arrow \N $, by the following formula:
%  $$ subgraphCapacity(P) = \sum_{\substack{e \in E(P)\\ s.t. layer(e) > 0}} capacity(e) $$
%
%    \item \emph{ safe capacity of a path} $P \subseteq H$, i.e., $safePathCapacity: \N \times \powerset(H) \arrow \N $, by the following formula:
%    $$ safePathCapacity(w, P) = \sum_{\substack{e \in E(P)\\ s.t. layer(e) > 0}} capacity(e) - w $$
%
%    \item \emph{safe capacity of a directed subgraph} $S \subseteq H$ with respect to vertices $u,v \in S$ such that all vertices of $S$ belong to a path from $u$ to $v$ , i.e., $safeSubgraphCapacity: \N \times S \times V(S) \times V(S) \arrow \N$ as follows:
%      $$safeSubgraphCapacity(w, u, v, S) = \min_{\substack{P \subseteq S \\ nonempty path from u to v}} safePathCapacity(P) $$
%
%      Let $m \in V$ be a a component of merge nodes managed by a loop condition node $c \in V'$. Also, let $S = \bigcup_{\substack{P \subseteq H \\ path from m to m}} P$.
%      \begin{itemize}
%        \item \emph{safe capacity of loop body } defined by $c$ is $safeLoopCapacity(w,c) = safeSubgraphCapacity(w, m, m, S)$.
%        \item \emph{capacity of loop body } defined by $c$ is $safeLoopCapacity(w,c) = SubgraphCapacity(w, m, m, S)$.
%      \end{itemize}
%
%  \end{itemize}
%\end{define}
%
%  Specifically we propose setting sizes of all buffers to $2*w$ except for the buffers leading from merge nodes to splits nodes in the loop condition scheme (definition \ref{TODO}). We need to fulfill the following conditions:
%  \begin{itemize}
%    \item Every loop (defined by $c \in V'$ (from the previous definition)) contains at most $safeLoopCapacity(w,c)$ data rows at every moment. 
%    \item For every cycle of every loop there exists a buffer which contains at least $w$ data rows, unless the number of data rows present in the cycle in question is lower than its limit.
%
%\begin{algorithm}
%
%\end{algorithm}
%
%
%
%\begin{define}[capacity of a path]
%  L
%  Let $G(V,E)$ be a flow graph, let $w \in \N$ be a number representing vector size and let $capacity: E arrow \N$ be a function denoting capacity assigned to a buffer represented by an edge of $E$. We shall define capacity of a path $P \subseteq G$, i.e., $pathCapacity: \N \times \powerset(G) \arrow \N $, by the following formula:
%  $$ pathCapacity(w, P) = \sum_{\substack{e \in E(P)\\ s.t. layer(e) > 0}} capacity(e) - w $$
%\end{define}


\mybeginclaim{unorderedproof}{Unordered solution}
We claim that the \emph{ordered crawler} (section \ref{ordered_crawler}) algorithm solves this problem if we make the following adjustments. In addition, we claim that this algorithm will always use the vectorized version of loop body until the termination phase is entered.
 \begin{itemize}
   \item All jumps lead to vectorized labels except for jumps in termination handlers.
   \item If $a$ and $b$ are processing bodies of merge nodes and $C$ is a component such that both $a$ and $b$ outputs data into $C$ then $a$ and $b$ get generated into the same (algorithm) partition.
   \item All buffers have capacity assigned to $bufferCapacity$ as defined by the definition \ref{def:capacities}.
   \item Limits of all loop condition nodes are set according to $limit$ as defined by the definition \ref{def:capacities}.
   \item Each time a partition receives data input, the terminating variable is set to $min(terminating,i)$ with i equal to the index of the partition which received data.
 \end{itemize}
We will again show the following points:
\begin{enumerate}
  \item Algorithm produces correct results (if it terminates).
  \item Algorithm does not enter an infinite loop during the pre-termination phase unless there is an infinite loop contained in the semantics of $G$.
  \item Algorithm terminates correctly.
\end{enumerate}
\begin{proof}[Proof of 1]
  All data rows are handled as consistent packs, so every data row is handled correctly.
\end{proof}
\begin{proof}[Proof of 2] So let there be a flow graph $G(V,E)$ and a sequence of data rows such that the described algorithm enters an infinite loop which does not process any data. Let $C$ be this loop. Let $t$ be topological ordering of a factor graph of $G$. 
  \item Again let $M = \{v \in C | \neg (\exists u \in C)( u <_t v \land (u,v) \in C)\}$. $M$ is empty, since every component has either all inputs sufficiently populated or none. 
    
    This means that the algorithm is either only descending or only ascending in the graph structure, which implies that it traces a loop. Thus, either all buffers on $C$ contain an insufficient amount of data or no buffer on $C$ has sufficient amount of space. But we have assigned buffer capacities in such manner that this cannot happen.
\end{proof}
\begin{proof}[Proof of 3]
  This is again a simple procedure of checking that every partition processes its data and increments the termination counter.
\end{proof}
\myendclaim

\begin{rem} 
  The partitioning algorithm may be easily adjusted for conversion of some flow graphs into their sequential equivalents. The simplest version will handle graphs which contain simple edges which bypass some control flow schemes. This algorithm may also be further refined to handle situations like parallel branching. The point of the adjustment lays in choosing a 'native' outgoing control flow node which will then be pasted on any bypassing edges or before any other control flow which does not match the 'native' control flow node. One question is how to solve some implementation details in order to prevent entering of infinite loops. Another question is how to optimise the resulting graphs since a naive implementation may produce highly inefficient results. 
\end{rem}



