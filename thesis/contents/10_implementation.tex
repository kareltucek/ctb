
\section{Graph algorithms}

Here we introduce employed graph-related algorithms. 

We provide code samples in a partially functional pseudo language inspired by C++11. We omit all unneccesary keywords, signatures and parts of signatures which are not necessary for semantical understanding. We do so to simplify and shorten the code.

Code samples shown in this chapter aim to explain the main ideas without all implementation details. The actual implementation of may be found in files \ttt{graph.h}, \ttt{graph\_factor.h} and \ttt{cf\_transformer.h}.

\algref{Graph crawler}
We implement most of our algorithms using a relatively simple crawling template. This template is designed to be usable for wide variety of tasks. Its semantics roughly corresponds to the following pseudo-code (exact implementation may be found at the very end of the \ttt{graph.h} header file). This template was designed to crawl graphs in topological order.

\mybeginfig %
\begin{code}
fun crawler<recurse, inverse>(node* n, fun f, fun g, list l = {0})
{
  if(!g(n))
    return
  if(recurse)
    foreach( u : parent of n)
      crawler(u, f, g)
  if(f(node))
    foreach( u : child of n)
      crawler(u, f, g)
}
\end{code}
\myendfig{crawlerapi}{Our callback-driven crawling template.} %

\begin{description}
  \item \ttt{l} list of edge layers to be used.
  \item \ttt{Child (parent)} of vertex v is a vertex u such that there exists an edge (v, u) ( (u,v) ).
  \item \ttt{f,g} are possibly effectfull functions of type $V \arrow bool$. The function \ttt{f} is designed to perform some work while the \ttt{g} function is designed to control which nodes are to be crawled.
  \item \ttt{Inverse} switches direction of this algorithm, i.e., makes it consider edges in an inversed direction.
  \item \ttt{Recurse} turns on and off the search of parents.
\end{description}

We implement the second recursive call using an out-of-scope queue which is passed implicitly to prevent some loops on call stack. This precaution reduces the maximum number of nested calls to the longest directed stroke\footnote{A path which may contain vertices multiple times} which is present. This functionality (if used properly) allows algorithms to be writen so that the maximum number of nested calls does not exceed the length of the longest directed \emph{path}. The actual implementation also handles crawling on a defined subset of graph layers passed by the \ttt{l} argument.

\algref{Topological search}
We implement topological search of connected partitions using the following snippet. This function is very useful since it stands for \ttt{foreach(v in topological order) f(v); }. If there is no topological ordering for the component in question, then this code is equivalent to an unordered \ttt{foreach}.

\mybeginfig %
\begin{code}
fun crawl_partition_topological(node* n, fun f)
{
  crawl<true, inverted>( n
    , (node* n){ f(n); n->lastpass = passid; return true;}
    , (node* n){ return n->lastpass != passid;}
  );
}
fun crawl_topological(fun f)
{
  passid++;
  foreach(vertex v)
    if(v->lastpass != passid)
      crawl_partition_topological(v, f);
}
\end{code}
\myendfig{crawlertopo}{Topological search algorithm.} %

There are only three things to note:
\begin{itemize}
  \item The \ttt{lastpass} variable is used in combination with the (out-of-scope) \ttt{passid} variable as an auxiliary mark which denotes whether a node was visited. The \ttt{passid} ensures that a new mark which was not yet used is used.
  \item This function is not reentrant as shown. In real implementation we use a bit more complex call which uses an out-of-scope set instead of the \ttt{passid} variable. 
  \item We could write this in an even simpler manner, using only the \ttt{g} callback. Unfortunately, such solution would enter an infine loop if there was a cycle in the presumably acyclic graph. This solution does not enter an infinite loop, which is the preferred behaviour. 
\end{itemize}

\algref{Cycle detection}
We detect cycles in two steps:
\begin{enumerate}
  \item We construct some ordering of nodes using the topological search.
  \item We check that the ordering is a correct topological ordering.
\end{enumerate}

Both these steps may be done by simple calls to the topological search algorithm.

\mybeginfig %
\begin{code}
fun find_cycle()
{
  int order = 0;
  node* node_on_cycle = NULL;
  crawl_topological((node* n){n->order = order++;});
  crawl_topological((node* n){
    forall(e output edge of n) 
      if(e->from->order > e->to->order)
        node_on_cycle = n;
  };
  return node_on_cycle;
}
\end{code}
\myendfig{findcycleapi}{Cycle detection algorithm.} %

\algref{Shortest path search}
For the purpose of shortest-path routeing, we maintain a map of size $| G |$ in every vertex. This map contains one record per every vertex of $G$. This record contains:

\begin{itemize}
  \item distance
  \item next node on a shortest path
\end{itemize}

This solution, despite being quite minimalistic, requires $O(n^2)$ memory, which may be a problem for big graphs. Since we use minimal path search only for the purpose of finding shortest width-conversion path, this limitation does not concern us much. An alternative would be running Dijkstra's algorithm on every request \cite{chapters}.

We fill these routing structures using the well known Bellman-Ford algorithm \cite{chapters} implemented using our callback machinery. Equivalent pseudo code may be:
\mybeginfig %
\begin{code}
foreach(vertex v)
{
  crawl<false,false>( v
    , (node* n){ recalculate n; return updated || first pass;}
    , (node* n){ return true }
  ); 
}
\end{code}
\myendfig{bellmanfordapi}{Pseudo code of the Bellman-Ford algorithm.} %

\algref{Factor graph construction}
Construction of a factor graph is again a simple process. The only interesting part is the second step in which we try to sort the components (pseudo) topologically even if no topological ordering exists.

We should remind the reader that we use two instances of the standard graph to to represent the graph and its factor graph. The actual implementation just uses inheritance to allow the factor graph to be a member of the graph (\ttt{class G: public graph\_t<...> \{ graph\_t<...> factor; \};}). For now, we will simply use the names \ttt{G} and \ttt{factorgraph}.
\begin{enumerate}
  \item The crawling algorithm is used to assign component ids\footnote{We use the term \emph{class id} in actual implementation. This is in accordance with standard algebraic terminology.} to all vertices. We show this in figure \ref{fig:factoralgclasses}.
  \item Then we try to remap component ids so that the components are in an order resembling our subjective feeling of a correct (pseudo) topological ordering. 
    \begin{itemize}
      \item This task is simple if topological ordering exists - a single pass by the topological search in the factor graph yields a map which is then used to reassign the ids. We show this in figure \ref{fig:factoralgorder1}
      \item If no topological ordering of components exists, we still try to return nicely-looking results. This makes sense since the underlying graph will usually have a topological ordering. 
        
        First, we assign some ordering to \emph{edges} on levels 0 and 1. We do this by the topological search, so we assume to get the edges ordered (mostly) topologically\footnote{Note that our use case is exactly that of graphs which are acyclic on levels 0 and 1}. Our observation is that some feasible ordering of components is an ordering induced by the order of input edges. Specifically, we pick the  maximum input edge which is less than every output edge of a component. We show this in figure \ref{fig:factoralgorder2}.
  \end{itemize}
  \item Finally, the vertices are gathered into components represented by vertices in the new graph structure (as shown in fig \ref{fig:factoralgtranslate}).
\end{enumerate}

\FloatBarrier

\mybeginfigloose
\begin{code}
crawl_topological((node* n){n->classid = -1;});
int classcount = 0;
foreach(node n in G)
  if(n->classid == -1)
  {
    crawl_partition_topological(n, (node* n){n->classid=classcount;});
    classcount++;
  }
\end{code}
\myendfig{factoralgclasses}{Factorisation -- class assignment.}

\mybeginfigloose
\begin{code}
map<int, int> translation;
int i = 0;
factorgraph->crawl_topological((node* n){
  translation[n->classid] = i++;
});
foreach(node n in G)
  n->classid = translation[n->classid];
\end{code}
\myendfig{factoralgorder1}{Factorisation -- construction of a translation map for acyclic graphs.}

\mybeginfigloose
\begin{code}
int order = 0;
factorgraph->crawl_topological(
  (node* n){ 
    foreach(e output edge of n) 
      e->order = order++;
  }
);
map<int, int> minouts;
map<int, int> maxins;
for(i in 0 .. classcount-1) 
{
  //this ensures that minouts values are always unique
  minouts[i] = MAXINT - classcount + i;
  maxins[i]= -1;
} 
factorgraph->crawl_topological(
  (node* n){
    foreach(e is output edge of n)
      minouts[n->classid] = min(e->order, minouts[n->classid]);
    foreach(e is input edge of n)
      maxins[n->classid] = max(e->order, maxins[n->classid]);
  }
); 
for(i in 0 .. classcount-1)
  maxins[i] = min(maxins[i], minouts[i]);
vector<int> translation = keys of maxins sorted by value;
foreach(node n in G)
  n->classid = translation[n->classid];
\end{code}
\myendfig{factoralgorder2}{Factorisation -- construction of a translation map for possibly cyclic graphs.}

\mybeginfigloose
\begin{code}
for( i in 0 .. classcount-1)
  create component i in factograph (i.e. a standard vertex)
foreach(node n in G)
  assign n to component n->classid of factorgraph;
\end{code}
\myendfig{factoralgtranslate}{Factorisation -- translation of ids.}

\FloatBarrier

\algref{Cycle removal}

We implement this algorithm as described by algorithm \ref{alg:cycleremalg}. We believe that the reader can imagine how our crawlers can be used to perform the mathematically described steps.

\section{Instruction representation}

\label{sec:instab}

We would like to shed some light on structure of the instruction table to make the internal workings of the generator clearer. We shall postpone exact field semantics into chapter \ref{sec:formats}, which is dedicated to api description. The architecture may be visualised by the following diagram:

\graph{instab}{Architectural diagram of the instruction table}

\begin{description}
  \item [Nodes] of this graph correspond to either `structs' or `classes'.
  \item [Edges] may be read as `a manages b' or `a contains b' or `a is responsible for'.
\end{description}

\begin{description}
  \item[Instruction table] contains:
    \begin{itemize}
      \item Containers of \emph{types}, \emph{operations}.
      \item Accumulated search table of \emph{expansions}.
      \item Api which provides mapping from identifiers to these structures.
      \item \emph{Tag handlers} which are used to restrict the set of employed instructions and their access api.
    \end{itemize}
  \item[Operation] class represents either logical operations or expansions. In our implementation every operation is allowed to have at most one output. This is w.l.o.g.. Operations contain/provide:
    \begin{itemize}
      \item \emph{Identifier}.
      \item Container of \emph{instructions} realising this operation.
      \item Container of \emph{expansions} which are identified by operation id of the operation.
      \item Operation semantics such as \emph{width}, a list of \emph{input types} and a list of \emph{output types}.
      \item Publicly available references to \emph{return types}.
      \item Api for retrieval of \emph{instruction patterns}. The generator communicates directly with an instance of the operation class, asking for results suitable for a specific width. The operation then returns patterns of the most suitable instruction which realises the operation.
    \end{itemize} 
  \item[Instruction] is a small structure which represents a target instruction. This structure contains:
    \begin{itemize}
      \item \emph{Width} information.
      \item List of \emph{tags}.
      \item \emph{Indicator} which indicates whether the instruction is suitable for the current pass of the generator.
      \item \emph{Instruction patterns}. This encompasses some predefined, specially handled fields and a map of user-named fields, which get outputted into different layers of the supplemented writer\footnote{This is implemented by means of one of our implicit containers.}.
    \end{itemize}
  \item[Expansion] may be seen as a special case of an operation or as placeholders which provide some information about what should be done with some part of a graph. All expansion nodes are supposed to be removed by some graph transformation prior to the generation and possibly replaced by new nodes or even by new subgraphs. The motivation for these nodes are exactly graph transformations, due to clash of the following two requirements:
    \begin{itemize}
      \item When generating code, we need to work only with specific type-aware instructions. 
      \item The graph transformations and node types which we have introduced are type independent. 
    \end{itemize}
    These expansions present a way of binding specific instructions to general transformations by providing a list of instruction identifiers identifying specific target instructions for specific type signatures. These expansions are hence allowed (and assumed) to be present in multiple instances with different type signatures. These contain the following fields:
    \begin{itemize}
      \item \emph{Transformation name} and \emph{transformer identifier}, which define which graph transformer should process them. We should note that graph transformers are free to ignore these identifiers.
      \item \emph{Transformation identifier}, which also acts as the operation id.
      \item \emph{Type signature}, which is used to choose specific expansion from the set of expansions identified by the same identifier.\footnote{This mechanism allows very simple introduction of type inference. This would be implemented as a graph transformation and its full control would still remain under control of the user.}
      \item List of \emph{instruction identifiers} which specify some target instructions for the expansion.
    \end{itemize}
    For instance, consider explicit buffers, defined in definition \ref{def:nodetypes1}. Buffers may be represented by single nodes in the input graph. This identifier may have two expansions defined. When the `cf' transformer is run, it should choose one of the expansions depending on types of neighbouring nodes and expand it to two new nodes.
    \mybeginfig
    \begin{center}
      \begin{tabular}{c|c|c|c|c|p{4cm}}
        identifier & inputs & outputs & name & transformer & list of inst.\\
        \hline
        BUFF & INT & INT & buffer & cf & BUFF\_ST\_INT, BUFF\_LD\_INT \\
        BUFF & BOOL & BOOL & buffer & cf & BUFF\_ST\_BOOL, BUFF\_LD\_BOOL 
      \end{tabular}
    \end{center}
    \myendfig{bufferexpansion}{Example of expansion semantics.}
  \item[Type] represents logical data type of the target architecture. It contains:
    \begin{itemize}
      \item Container of \emph{type versions}.
      \item Container of \emph{type conversions}.
      \item \emph{Api} which resolves requests for instruction patterns of type versions and conversions.
    \end{itemize}
  \item[Type version] is a variation of a data type specific for a width. It contains:
    \begin{itemize}
      \item \emph{Instruction pattern} representation of this type in the target language.
      \item \emph{Width}.
    \end{itemize}
    For instance, the type \emph{bool} may have \emph{bool/1}, \emph{int/16}, \emph{int/32} and \emph{\_m128i/128}  as its type versions. (\emph{type pattern/width}).
  \item[Width conversion] is a structure which represents a width conversion between two widths of a data type. These contain:
    \begin{itemize}
      \item \emph{Input width} and \emph{Output width}.
      \item \emph{Tags}.
      \item \emph{Flag} indicating whether tag requirements are satisfied.
      \item \emph{Instruction patterns}.
    \end{itemize}
\end{description}

Consider again code fragment given in figure \ref{fig:vectorizedfragment} (fragment of the vectorized generator). Lines 1,2,4,7,8 were generated from instruction patterns of \emph{instructions}. The lines 3,5 and 6 were generated from instruction patterns of two \emph{width conversions} (the lines 5 and 6 are two patterns defined by a common width conversion). All type specifiers present in the figure were resolved from input and output widths and types of instructions and of width conversions. The patterns of instructions and types were composed together by internal mechanics of the writer. (However, the form of this composition was defined by the form of the pattern. The writer itself is an independent text processor which has \emph{no} information about internal needs of the generator.)

The example in figure \ref{fig:expeval} shows how a single line of the resulting code may be composed from various patterns. We show a single call to the writer as may be issued by the generator. Some context is provided via string declarations. The real situation is more complicated since this example does not consider vectorization. Assume the target environment to be represented by a fictive \ttt{clang} alias environment which inherits the \ttt{generator} alias environment. 

This example illustrates the context of the generator, of instruction patterns and of instruction-related structures. However, main point of this example lays in the principle of the text processing environment, e.g., of cooperation between a writer and alias environments.  Understanding of the principle of alias environments is crutial for understanding of the entire system.


\mybeginfig
\begin{loosecode}
//determined by the node type
string pattern_type = "$opexpr";
//retrieved from the instruction table
string type_code = "int";
string ins_code = "$arg1 + $arg2"; 
//memoized names of variables containing 
//  results of the operations of vertices a and b
string arg1 = "var_a";
string arg2 = "var_b";
//a new variable name constructed from id of vertex c
string name = "var_c";
//the actual call
w.print("$opexpr", type_code, ins_code, width, arg1, arg2, name);
//the process of evaluation
//    ("$opexpr" -> "$type $name = $operation;") //by clang aliasenv
//"$type $name = $operation;"                //intermediate result
//    ("$type" -> "$1")                      //by generator aliasenv
//    ("$1" -> type_code)                    //by writer
//"int $name = $operation;"
//    ("$name" -> "$6")                      //by generator aliasenv
//    ("$6" -> name)                         //by writer
//"int var_c = $arg1 + $arg2;"
//    ("$arg1" -> "$4")                      //by generator aliasenv
//    ("$4" -> arg1)                         //by writer
//"int var_c = var_a + $arg2;"
//    ("$arg2" -> "$5")                      //by generator aliasenv
//    ("$5" -> arg2)                         //by writer
//"int var_c = var_a + var_b;"               //the final result
\end{loosecode}
\myendfig{expeval}{Example of instruction pattern evaluation.}


\begin{description}
  \item \ttt{type\_code, ins\_code, pattern\_type, arg1, arg2} are some string variables which were retrieved from contextual information, i.e., either directly or indirectly from the structure of the processed graph for from instruction tables.
  \item \ttt{w.print...} is the actual code which prints an instruction pattern into a writer wich acts as data sink for the generator.
  \item \ttt{comments} after the call show intermediate results of the writer and the flow of evaluation.
\end{description}




